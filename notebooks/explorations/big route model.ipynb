{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dbanalysis import stop_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying some different models on a single stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = stop_tools.random_stop_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor as rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'dayofservice', 'tripid', 'plannedtime_arr_from',\n",
       "       'plannedtime_dep_from', 'actualtime_arr_from', 'actualtime_dep_from',\n",
       "       'plannedtime_arr_to', 'actualtime_arr_to', 'routeid', 'fromstop',\n",
       "       'tostop', 'traveltime', 'dwelltime', 'distance', 'speed', 'dt', 'date',\n",
       "       'day', 'month', 'hour', 'year', 'dewpt', 'msl', 'rain', 'rhum', 'temp',\n",
       "       'vappr', 'wetb'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month']=df['dt'].dt.month\n",
    "train = df[df['month']<5]\n",
    "test=df[df['month']>=5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15526, 29)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8107, 29)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'dayofservice', 'tripid', 'plannedtime_arr_from',\n",
       "       'plannedtime_dep_from', 'actualtime_arr_from', 'actualtime_dep_from',\n",
       "       'plannedtime_arr_to', 'actualtime_arr_to', 'routeid', 'fromstop',\n",
       "       'tostop', 'traveltime', 'dwelltime', 'distance', 'speed', 'dt', 'date',\n",
       "       'day', 'month', 'hour', 'year', 'dewpt', 'msl', 'rain', 'rhum', 'temp',\n",
       "       'vappr', 'wetb'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day']=df['dt'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = rf(max_depth=100).fit(train[['month','hour','day','actualtime_arr_from','actualtime_dep_from','rain','rhum','temp','msl','wetb']],train['traveltime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = regr.predict(test[['month','hour','day','actualtime_arr_from','actualtime_dep_from','rain','rhum','temp','msl','wetb']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.008918218823236"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_absolute_error(test['traveltime'],preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.21138020631965593"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2_score(test['traveltime'],preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "msk = np.random.rand(len(df))<0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()\n",
    "train = df[msk]\n",
    "test = df[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.767603833865813"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = rf(max_depth=100).fit(train[['month','hour','day','actualtime_arr_from','actualtime_dep_from','rain','rhum','temp','msl','wetb']],train['traveltime'])\n",
    "preds = regr.predict(test[['month','hour','day','actualtime_arr_from','actualtime_dep_from','rain','rhum','temp','msl','wetb']])\n",
    "metrics.mean_absolute_error(test['traveltime'],preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['act2']=df['actualtime_arr_from']**2\n",
    "df['act3']=df['actualtime_arr_from']**3\n",
    "df['rain2']=df['rain']**2\n",
    "df['rain3']=df['rain']**3\n",
    "df['day2']=df['day']**2\n",
    "df['day3']=df['day']**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['month','hour','day','actualtime_arr_from','actualtime_dep_from','rain','rhum','temp','msl','wetb','act2','act3','rain2','rain3','day2','day3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['act2' 'act3' 'rain2' 'rain3' 'day2' 'day3'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-776ed58c6065>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mregr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'traveltime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'traveltime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2677\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2678\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2679\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2680\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2681\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2721\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2722\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2723\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2724\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[0;32m-> 1327\u001b[0;31m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['act2' 'act3' 'rain2' 'rain3' 'day2' 'day3'] not in index\""
     ]
    }
   ],
   "source": [
    "regr = rf(max_depth=100).fit(train[features],train['traveltime'])\n",
    "preds = regr.predict(test[features])\n",
    "metrics.mean_absolute_error(test['traveltime'],preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = LinearRegression(fit_intercept=True).fit(train[features],train['traveltime'])\n",
    "preds=regr.predict(test[features])\n",
    "metrics.mean_absolute_error(test['traveltime'],preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor as ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = ml().fit(train[features],train['actualtime_arr_to'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=regr.predict(test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_absolute_error(test['actualtime_arr_to'],preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['month',\n",
    " 'hour',\n",
    " 'day',\n",
    " 'actualtime_arr_from',\n",
    " 'actualtime_dep_from',\n",
    " 'rain',\n",
    " 'rhum',\n",
    " 'temp',\n",
    " 'msl',\n",
    " 'wetb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr =svm.SVR().fit(train[features],train['traveltime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=regr.predict(test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dumb method\n",
    "preds = pd.Series([test['traveltime'].mean() for i in range(len(test))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_absolute_error(test['traveltime'],preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The point here then is that predicting the mean isn't really so bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "routes = json.loads(open('/home/student/dbanalysis/dbanalysis/resources/trimmed_routes.json','r').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eh fuck this\n",
    "\n",
    "\n",
    "# Making a singular gigantic model of a route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=routes['15'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dbanalysis import stop_tools\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_concat=[]\n",
    "for i in range(1, len(r)-1):\n",
    "    a=r[i]\n",
    "    b=r[i+1]\n",
    "    df=stop_tools.get_stop_link(a,b,merge_weather=True)\n",
    "    to_concat.append(df)\n",
    "    \n",
    "df = pd.concat(to_concat,axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding the approx distances from the first stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s_getter =stop_tools.stop_getter()\n",
    "total_distance = 0\n",
    "route_distances = {r[1]:0}\n",
    "for i in range(1, len(r)-1):\n",
    "    distance = s_getter.get_stop_distance(str(r[i]),str(r[i+1]))\n",
    "    \n",
    "    total_distance += distance\n",
    "    route_distances[r[i+1]]=total_distance\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['distance']=df['stopA'].apply(lambda x: route_distances[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hacking in the time of leaving the first stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys= df[df['stopA']==6318]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "to_concat = []\n",
    "## no this doesn't work\n",
    "#for row in keys.itertuples():\n",
    "\n",
    "  #  \n",
    " #   temp_df = df[(df['dayofservice']==row[1]) & (df['tripid']==row[2])]\n",
    "   # temp_df['base_time_dep'] = row[5]\n",
    "#    to_concat.append(temp_df)\n",
    "\n",
    "\n",
    "keys['base_time_dep']=keys['actualtime_arr_from']\n",
    "keys2=keys[['tripid','dayofservice','base_time_dep']]\n",
    "full_df = pd.merge(df,keys2,on=['dayofservice','tripid'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84703"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df['base_time_dep'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we seem to have lost a lot of samples unfortunately, by virtue of following this process. Maybe we need to like ... use the scheduled departure times instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['traveltime']=full_df['actualtime_arr_from']-full_df['base_time_dep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting and adding date time information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "msk = np.random.rand(len(full_df))<0.8\n",
    "test = full_df[msk]\n",
    "\n",
    "train = full_df[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df=full_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_format = \"%d-%b-%y %H:%M:%S\"\n",
    "full_df['dt']=pd.to_datetime(full_df['dayofservice'],format=time_format)\n",
    "full_df['dayofweek']=full_df['dt'].dt.dayofweek\n",
    "full_df['month']=full_df['dt'].dt.month\n",
    "full_df['weekend']=full_df['dayofweek']>4\n",
    "full_df['year']=full_df['dt'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=full_df[full_df['year']==2016]\n",
    "test = full_df[full_df['year']==2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "features=['hour','weekend','month','dayofweek','rhum','rain','vappr','wetb','distance','base_time_dep','msl','temp']\n",
    "regr=LinearRegression(fit_intercept=True).fit(train[features],train['actualtime_arr_from'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321.6330604006038\n",
      "0.999340977841599\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "predicts=regr.predict(test[features])\n",
    "print(metrics.mean_absolute_error(test['actualtime_arr_from'],predicts))\n",
    "print(metrics.r2_score(test['actualtime_arr_from'],predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['weekend']=full_df['dayofweek']>4\n",
    "features=['hour','weekend','month','dayofweek','rhum','rain','vappr','wetb','distance','base_time_dep','msl','temp']\n",
    "regr=LinearRegression(fit_intercept=True).fit(train[features],train['traveltime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321.6330604005971\n",
      "0.9280429215025939\n"
     ]
    }
   ],
   "source": [
    "predicts=regr.predict(test[features])\n",
    "print(metrics.mean_absolute_error(test['traveltime'],predicts))\n",
    "print(metrics.r2_score(test['traveltime'],predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model works, but there is clearly something bullshit about these r2 scores\n",
    "\n",
    "... Testing again, but this time only on a single variable (the time taken to get from the first stop to the last stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = full_df[full_df['distance']==22.60855934258725]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6593"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534.2927397275263\n",
      "0.22018558098111973\n"
     ]
    }
   ],
   "source": [
    "predicts=regr.predict(test2[features])\n",
    "print(metrics.mean_absolute_error(test2['traveltime'],predicts))\n",
    "print(metrics.r2_score(test2['traveltime'],predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As you can see\n",
    "\n",
    "# a) The r2 score has collapsed now that we're testing only a singular variable\n",
    "\n",
    "# b) The mean absolute error has gone up - we are about 10 minutes off in our predictions for how long it takes the bus to travel the entirety of the route"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over all, I'm going to say that the only gains from making 'whole route models' are going to be in terms of optimizing our compute process, not in terms of accuracy.\n",
    "\n",
    "## The two step dwelltime/traveltime modelling process still makes way more sense I reckon\n",
    "\n",
    "With this gigantic route model approach we're:\n",
    "1. Forced to drop a lot of relevant data from our analysis (the links that are shared by multiple routes)\n",
    "2. Trying to approximate a horrendously complicated, messy, non linear function.\n",
    "3. Unable to adequately separate the prediction of dwell time and the prediction of travel time.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# With fake neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = ml().fit(train[features],train['traveltime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts=regr.predict(test2[features])\n",
    "print(metrics.mean_absolute_error(test2['traveltime'],predicts))\n",
    "print(metrics.r2_score(test2['traveltime'],predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It also takes a shameful amount of time to train a neural network model on this ... \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And we only save on 5 seconds\n",
    "\n",
    "# With  svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = svm.SVR().fit(train[features],train['traveltime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('svm.pickle','wb') as handle:\n",
    "    pickle.dump(regr,handle,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('svm.pickle','rb') as handle:\n",
    "    regr = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### All stops ###\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('### All stops ###')\n",
    "predicts=regr.predict(test[features])\n",
    "print(metrics.mean_absolute_error(test['traveltime'],predicts))\n",
    "print(metrics.r2_score(test['traveltime'],predicts))\n",
    "predicts=regr.predict(test2[features])\n",
    "print('\\n\\n ### One Stop ###')\n",
    "print(metrics.mean_absolute_error(test2['traveltime'],predicts))\n",
    "print(metrics.r2_score(test2['traveltime'],predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2591.2068976663527\n",
      "-11.535763697371335\n"
     ]
    }
   ],
   "source": [
    "predicts=regr.predict(test2[features])\n",
    "from sklearn import metrics\n",
    "print(metrics.mean_absolute_error(test2['traveltime'],predicts))\n",
    "print(metrics.r2_score(test2['traveltime'],predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forget about training time - svm seems to take forever to predict?\n",
    "\n",
    "Also the results are crap. Clearly will haven to understand what this model actually does, before fine tuning it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['hour','weekend','month','dayofweek','rhum','rain','vappr','wetb','distance','base_time_dep','msl','temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor as rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['month',\n",
       " 'hour',\n",
       " 'day',\n",
       " 'actualtime_arr_from',\n",
       " 'actualtime_dep_from',\n",
       " 'rain',\n",
       " 'rhum',\n",
       " 'temp',\n",
       " 'msl',\n",
       " 'wetb']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.19439372,  0.42661594,  0.91399099,  2.12746783,\n",
       "        2.13710899,  2.73836243,  3.05509448,  3.47239308,  3.98918733,\n",
       "        4.29713731,  4.60077595,  5.07080026,  5.22224552,  5.52456992,\n",
       "        5.73902979,  6.13097876,  6.47090175,  6.80926407,  7.12874632,\n",
       "        7.41718128,  7.73113298,  8.15250246,  8.459664  ,  8.79233752,\n",
       "        9.06522538,  9.34944473,  9.63199619,  9.91663643, 10.38606964,\n",
       "       11.79891293, 12.14116219, 12.56124053, 13.38822997, 13.59259852,\n",
       "       13.8187145 , 13.9437401 , 14.33519184, 14.54172718, 14.83736879,\n",
       "       15.17371397, 15.38787347, 15.67475222, 15.87786843, 16.06248638,\n",
       "       16.37022232, 16.61976575, 16.90819453, 17.16837317, 17.39439661,\n",
       "       17.86033059, 18.30079427, 19.16280228, 19.600695  , 20.9327889 ,\n",
       "       21.35775595, 22.28254239,  2.41355696, 10.07682693, 14.10590383,\n",
       "       18.76220611, 19.86110042, 20.63406303, 22.17246364, 22.60855934,\n",
       "       20.46557701, 13.00315193, 11.24524183, 11.02329844])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['distance'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regr = rf().fit(train[features],train['traveltime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378.17156074624603\n",
      "0.5809780256092053\n"
     ]
    }
   ],
   "source": [
    "test2 = test[test['distance']==test['distance'].max()]\n",
    "predicts=regr.predict(test2[features])\n",
    "\n",
    "from sklearn import metrics\n",
    "print(metrics.mean_absolute_error(test2['traveltime'],predicts))\n",
    "print(metrics.r2_score(test2['traveltime'],predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-53d56cbe8781>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.tools'"
     ]
    }
   ],
   "source": [
    "from sklearn.tools import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/data/forestdump.pickle','wb') as handle:\n",
    "    pickle.dump(regr,handle,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.816852303727892"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((abs(test2['traveltime']-predicts)/test2['traveltime'])*100).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269.99855513307983\n",
      "0.7703147250617991\n"
     ]
    }
   ],
   "source": [
    "predicts=regr.predict(test2[features])\n",
    "\n",
    "from sklearn import metrics\n",
    "print(metrics.mean_absolute_error(test2['traveltime'],predicts))\n",
    "print(metrics.r2_score(test2['traveltime'],predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.73836243])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[(test['distance']>2.537109) & (test['distance']<3)]['distance'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This seems to be the best candidate so far\n",
    "\n",
    "Large reduction in error from what we saw while using linear and neural networks.\n",
    "\n",
    "Why not cluster the data then to find the best candidates for this kind of thing? Somehow minimize the size of the models through sampling important data or something. Yeah. That kind of thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# With k nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312.9153992395437\n",
      "0.6483993230964855\n"
     ]
    }
   ],
   "source": [
    "regr = KNeighborsRegressor(1).fit(train[features],train['traveltime'])\n",
    "predicts=regr.predict(test2[features])\n",
    "print(metrics.mean_absolute_error(test2['traveltime'],predicts))\n",
    "print(metrics.r2_score(test2['traveltime'],predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interestingly, upping the number of neighbors seems to push the results into negative territory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All that said, the biggest problem with the big route model is that we're dropping so much data\n",
    "\n",
    "### How to use the rows of data that come from different routes? Is there a legitimate way to use them even?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Bascially have to do this notebook again with a 2016/2017 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hour',\n",
       " 'weekend',\n",
       " 'month',\n",
       " 'dayofweek',\n",
       " 'rhum',\n",
       " 'rain',\n",
       " 'vappr',\n",
       " 'wetb',\n",
       " 'distance',\n",
       " 'base_time_dep',\n",
       " 'msl',\n",
       " 'temp']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
