{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dbanalysis import stop_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying some different models on a single stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = stop_tools.random_stop_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor as rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'dayofservice', 'tripid', 'plannedtime_arr_from',\n",
       "       'plannedtime_dep_from', 'actualtime_arr_from', 'actualtime_dep_from',\n",
       "       'plannedtime_arr_to', 'actualtime_arr_to', 'routeid', 'fromstop',\n",
       "       'tostop', 'traveltime', 'dwelltime', 'distance', 'speed', 'date',\n",
       "       'hour', 'dewpt', 'msl', 'rain', 'rhum', 'temp', 'vappr', 'wetb', 'dt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month']=df['dt'].dt.month\n",
    "train = df[df['month']<5]\n",
    "test=df[df['month']>=5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1272, 27)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(413, 27)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'dayofservice', 'tripid', 'plannedtime_arr_from',\n",
       "       'plannedtime_dep_from', 'actualtime_arr_from', 'actualtime_dep_from',\n",
       "       'plannedtime_arr_to', 'actualtime_arr_to', 'routeid', 'fromstop',\n",
       "       'tostop', 'traveltime', 'dwelltime', 'distance', 'speed', 'date',\n",
       "       'hour', 'dewpt', 'msl', 'rain', 'rhum', 'temp', 'vappr', 'wetb', 'dt',\n",
       "       'month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day']=df['dt'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['day'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-dfb8d50b5b52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mregr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'month'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'hour'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'day'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'actualtime_arr_from'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'actualtime_dep_from'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rain'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rhum'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'temp'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'msl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wetb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'traveltime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2677\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2678\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2679\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2680\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2681\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2721\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2722\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2723\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2724\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[0;32m-> 1327\u001b[0;31m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['day'] not in index\""
     ]
    }
   ],
   "source": [
    "regr = rf(max_depth=100).fit(train[['month','hour','day','actualtime_arr_from','actualtime_dep_from','rain','rhum','temp','msl','wetb']],train['traveltime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = regr.predict(test[['month','hour','day','actualtime_arr_from','actualtime_dep_from','rain','rhum','temp','msl','wetb']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_absolute_error(test['traveltime'],preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.r2_score(test['traveltime'],preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "msk = np.random.rand(len(df))<0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()\n",
    "train = df[msk]\n",
    "test = df[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = rf(max_depth=100).fit(train[['month','hour','day','actualtime_arr_from','actualtime_dep_from','rain','rhum','temp','msl','wetb']],train['traveltime'])\n",
    "preds = regr.predict(test[['month','hour','day','actualtime_arr_from','actualtime_dep_from','rain','rhum','temp','msl','wetb']])\n",
    "metrics.mean_absolute_error(test['traveltime'],preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['act2']=df['actualtime_arr_from']**2\n",
    "df['act3']=df['actualtime_arr_from']**3\n",
    "df['rain2']=df['rain']**2\n",
    "df['rain3']=df['rain']**3\n",
    "df['day2']=df['day']**2\n",
    "df['day3']=df['day']**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['month','hour','day','actualtime_arr_from','actualtime_dep_from','rain','rhum','temp','msl','wetb','act2','act3','rain2','rain3','day2','day3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = rf(max_depth=100).fit(train[features],train['traveltime'])\n",
    "preds = regr.predict(test[features])\n",
    "metrics.mean_absolute_error(test['traveltime'],preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = LinearRegression(fit_intercept=True).fit(train[features],train['traveltime'])\n",
    "preds=regr.predict(test[features])\n",
    "metrics.mean_absolute_error(test['traveltime'],preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor as ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = ml().fit(train[features],train['actualtime_arr_to'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=regr.predict(test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_absolute_error(test['actualtime_arr_to'],preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['month',\n",
    " 'hour',\n",
    " 'day',\n",
    " 'actualtime_arr_from',\n",
    " 'actualtime_dep_from',\n",
    " 'rain',\n",
    " 'rhum',\n",
    " 'temp',\n",
    " 'msl',\n",
    " 'wetb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr =svm.SVR().fit(train[features],train['traveltime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=regr.predict(test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dumb method\n",
    "preds = pd.Series([test['traveltime'].mean() for i in range(len(test))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_absolute_error(test['traveltime'],preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The point here then is that predicting the mean isn't really so bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "routes = json.loads(open('/home/student/dbanalysis/dbanalysis/resources/trimmed_routes.json','r').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eh fuck this\n",
    "\n",
    "\n",
    "# Making a singular gigantic model of a route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=routes['15'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dbanalysis import stop_tools\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_concat=[]\n",
    "for i in range(1, len(r)-1):\n",
    "    a=r[i]\n",
    "    b=r[i+1]\n",
    "    df=stop_tools.get_stop_link(a,b,merge_weather=True)\n",
    "    to_concat.append(df)\n",
    "    \n",
    "df = pd.concat(to_concat,axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding the approx distances from the first stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s_getter =stop_tools.stop_getter()\n",
    "total_distance = 0\n",
    "route_distances = {r[1]:0}\n",
    "for i in range(1, len(r)-1):\n",
    "    distance = s_getter.get_stop_distance(str(r[i]),str(r[i+1]))\n",
    "    \n",
    "    total_distance += distance\n",
    "    route_distances[r[i+1]]=total_distance\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['distance']=df['stopA'].apply(lambda x: route_distances[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hacking in the time of leaving the first stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys= df[df['stopA']==6318]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "to_concat = []\n",
    "## no this doesn't work\n",
    "#for row in keys.itertuples():\n",
    "\n",
    "  #  \n",
    " #   temp_df = df[(df['dayofservice']==row[1]) & (df['tripid']==row[2])]\n",
    "   # temp_df['base_time_dep'] = row[5]\n",
    "#    to_concat.append(temp_df)\n",
    "\n",
    "\n",
    "keys['base_time_dep']=keys['actualtime_arr_from']\n",
    "keys2=keys[['tripid','dayofservice','base_time_dep']]\n",
    "full_df = pd.merge(df,keys2,on=['dayofservice','tripid'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['base_time_dep'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we seem to have lost a lot of samples unfortunately, by virtue of following this process. Maybe we need to like ... use the scheduled departure times instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['traveltime']=full_df['actualtime_arr_from']-full_df['base_time_dep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting and adding date time information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "msk = np.random.rand(len(full_df))<0.8\n",
    "test = full_df[msk]\n",
    "\n",
    "train = full_df[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df=full_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_format = \"%d-%b-%y %H:%M:%S\"\n",
    "full_df['dt']=pd.to_datetime(full_df['dayofservice'],format=time_format)\n",
    "full_df['dayofweek']=full_df['dt'].dt.dayofweek\n",
    "full_df['month']=full_df['dt'].dt.month\n",
    "full_df['weekend']=full_df['dayofweek']>4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "features=['hour','weekend','month','dayofweek','rhum','rain','vappr','wetb','distance','base_time_dep','msl','temp']\n",
    "regr=LinearRegression(fit_intercept=True).fit(train[features],train['actualtime_arr_from'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326.73161901369065\n",
      "0.9993193909641614\n"
     ]
    }
   ],
   "source": [
    "predicts=regr.predict(test[features])\n",
    "print(metrics.mean_absolute_error(test['actualtime_arr_from'],predicts))\n",
    "print(metrics.r2_score(test['actualtime_arr_from'],predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['weekend']=full_df['dayofweek']>4\n",
    "features=['hour','weekend','month','dayofweek','rhum','rain','vappr','wetb','distance','base_time_dep','msl','temp']\n",
    "regr=LinearRegression(fit_intercept=True).fit(train[features],train['traveltime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326.7316190136915\n",
      "0.9278256914020145\n"
     ]
    }
   ],
   "source": [
    "predicts=regr.predict(test[features])\n",
    "print(metrics.mean_absolute_error(test['traveltime'],predicts))\n",
    "print(metrics.r2_score(test['traveltime'],predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model works, but there is clearly something bullshit about these r2 scores\n",
    "\n",
    "... Testing again, but this time only on a single variable (the time taken to get from the first stop to the last stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = full_df[full_df['distance']==22.60855934258725]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6593"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547.6833167352945\n",
      "0.21055628133687754\n"
     ]
    }
   ],
   "source": [
    "predicts=regr.predict(test2[features])\n",
    "print(metrics.mean_absolute_error(test2['traveltime'],predicts))\n",
    "print(metrics.r2_score(test2['traveltime'],predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As you can see\n",
    "\n",
    "# a) The r2 score has collapsed now that we're testing only a singular variable\n",
    "\n",
    "# b) The mean absolute error has gone up - we are about 10 minutes off in our predictions for how long it takes the bus to travel the entirety of the route"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over all, I'm going to say that the only gains from making 'whole route models' are going to be in terms of optimizing our compute process, not in terms of accuracy.\n",
    "\n",
    "## The two step dwelltime/traveltime modelling process still makes way more sense I reckon\n",
    "\n",
    "With this gigantic route model approach we're:\n",
    "1. Forced to drop a lot of relevant data from our analysis (the links that are shared by multiple routes)\n",
    "2. Trying to approximate a horrendously complicated, messy, non linear function.\n",
    "3. Unable to adequately separate the prediction of dwell time and the prediction of travel time.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# With fake neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = ml().fit(train[features],train['traveltime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts=regr.predict(test2[features])\n",
    "print(metrics.mean_absolute_error(test2['traveltime'],predicts))\n",
    "print(metrics.r2_score(test2['traveltime'],predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It also takes a shameful amount of time to train a neural network model on this ... \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And we only save on 5 seconds\n",
    "\n",
    "# With  svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = svm.SVR().fit(train[features],train['traveltime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('svm.pickle','wb') as handle:\n",
    "    pickle.dump(regr,handle,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('svm.pickle','rb') as handle:\n",
    "    regr = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### All stops ###\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('### All stops ###')\n",
    "predicts=regr.predict(test[features])\n",
    "print(metrics.mean_absolute_error(test['traveltime'],predicts))\n",
    "print(metrics.r2_score(test['traveltime'],predicts))\n",
    "predicts=regr.predict(test2[features])\n",
    "print('\\n\\n ### One Stop ###')\n",
    "print(metrics.mean_absolute_error(test2['traveltime'],predicts))\n",
    "print(metrics.r2_score(test2['traveltime'],predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2591.2068976663527\n",
      "-11.535763697371335\n"
     ]
    }
   ],
   "source": [
    "predicts=regr.predict(test2[features])\n",
    "from sklearn import metrics\n",
    "print(metrics.mean_absolute_error(test2['traveltime'],predicts))\n",
    "print(metrics.r2_score(test2['traveltime'],predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forget about training time - svm seems to take forever to predict?\n",
    "\n",
    "Also the results are crap. Clearly will haven to understand what this model actually does, before fine tuning it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor as rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = rf().fit(train[features],train['traveltime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158.13037644084906\n",
      "0.9795461178340256\n"
     ]
    }
   ],
   "source": [
    "test2 = test[test['distance']==22.60855934258725]\n",
    "predicts=regr.predict(test[features])\n",
    "\n",
    "from sklearn import metrics\n",
    "print(metrics.mean_absolute_error(test['traveltime'],predicts))\n",
    "print(metrics.r2_score(test['traveltime'],predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269.99855513307983\n",
      "0.7703147250617991\n"
     ]
    }
   ],
   "source": [
    "predicts=regr.predict(test2[features])\n",
    "\n",
    "from sklearn import metrics\n",
    "print(metrics.mean_absolute_error(test2['traveltime'],predicts))\n",
    "print(metrics.r2_score(test2['traveltime'],predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This seems to be the best candidate so far\n",
    "\n",
    "Large reduction in error from what we saw while using linear and neural networks.\n",
    "\n",
    "Why not cluster the data then to find the best candidates for this kind of thing? Somehow minimize the size of the models through sampling important data or something. Yeah. That kind of thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# With k nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312.9153992395437\n",
      "0.6483993230964855\n"
     ]
    }
   ],
   "source": [
    "regr = KNeighborsRegressor(1).fit(train[features],train['traveltime'])\n",
    "predicts=regr.predict(test2[features])\n",
    "print(metrics.mean_absolute_error(test2['traveltime'],predicts))\n",
    "print(metrics.r2_score(test2['traveltime'],predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interestingly, upping the number of neighbors seems to push the results into negative territory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All that said, the biggest problem with the big route model is that we're dropping so much data\n",
    "\n",
    "### How to use the rows of data that come from different routes? Is there a legitimate way to use them even?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
