import os
from dbanalysis.models import BRModel
from subprocess import call
base_directory = '/data/BRModels'
call(['mkdir',base_directory])
call(['mkdir',base_directory+'/models'])
call(['mkdir',base_directory+'/logs'])
models_directory = '/data/BRModels/models/'
logs_directory = '/data/BRModels/logs/'
import json
routes = json.loads(open('/home/student/dbanalysis/dbanalysis/resources/trimmed_routes.json').read())
for route in routes:

    for variation in range(0, len(routes[route])):

        model = BRM(route,variation,rgr_type='Neural',features = [])
        import numpy as np
        msk = np.random.rand(len(model.data)) < 0.5
        #simply to big to use all of the data.
        #shame we don't have a more elegant approach to this
        model.data = model.data[msk]
        from sklearn.preprocessing import MinMaxScaler as mms
        model.X_transformer = mms().fit(model.data[model.features])
        model.Y_transformer = mms().fit(model.data['traveltime'])
        train_X = model.X_transformer.transform(model.data[model.features])
        train_Y = model.Y_transformer.transfrom(model.data['traveltime'])
        del(model.data)
        model.model = model.rgr.fit(train_X,train_Y)
        del(train_X)
        del(train_Y)
        
